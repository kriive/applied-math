\documentclass{article}
\usepackage[italian]{babel}
\usepackage{hyperref}
\usepackage{amsthm}
\usepackage{amsmath}
\usepackage{amssymb}

% Title Page
\title{Matematica Applicata}
\author{Manuel Romei \\ \href{mailto:manuel.romei@studenti.unipr.it}{manuel.romei@studenti.unipr.it}}
\date{a.a. 2021/2022}

\theoremstyle{plain}
\newtheorem{teorema}{Teorema}

\theoremstyle{plain}
\newtheorem*{teorema*}{Teorema}

\theoremstyle{definition}
\newtheorem{definizione}{Definizione}

\theoremstyle{definition}
\newtheorem{esempio}{Esempio}

\begin{document}
\maketitle

\begin{abstract}
	Questo documento riassume i concetti appresi durante le lezioni dell'anno accademico 2021/2022 di Matematica Applicata. Essendo io un aspirante ingegnere non aspettatevi troppo rigore matematico, cercherò tuttavia di fare del mio meglio.
\end{abstract}

\section{Interpolazione numerica}
Il problema dell'interpolazione numerica trova numerose applicazioni in diverse discipline scientifiche. In sintesi, il problema si può riassumere in questo modo: data una serie di punti campionati, trovare un'espressione polinomiale che ne approssimi l'andamento. Questa curva approssimante potrà ricalcare in maniera più o meno precisa la curva originale, a seconda dei nostri requisiti.

Prima di arrivare ad un primo teorema, facciamo alcuni esempi che dimostrino come questo problema sia già stato trattato in altri ambiti.

\begin{esempio}
	Costruire una funzione $p(x)$ che passi per i punti assegnati $(x_0, y_0)=(-1,2), (x_1, y_1)=(0,1), (x_2, y_2)=(1,2)$.
\end{esempio}

Consideriamo un polinomio con grado minore od uguale a 2, cioè $p(x)\in \mathcal{P}_{2}$. Il polinomio sarà della forma $p(x)=a_0+a_{1}x+a_{2}x^2$. Abbiamo 3 vincoli e 3 gradi di libertà, quindi costruiremo un sistema lineare di 3 equazioni e 3 incognite per trovare i coefficienti $a_0$, $a_1$ e $a_2$ che soddisfino il passaggio.

\begin{equation*}
	\left\{
	\begin{alignedat}{3}
		% R & L   &  R & L   &  R & L 
		a_{0} & +{} &  a_{1}(-1) & +{} & a_{2}(-1)^2 & = 2 \\
		a_{0} & +{} &  a_{1}(0) & +{} &  a_{2}(0)^2 & = 1 \\
		a_{0} & +{} & a_{1}(1) & +{} & a_{2}(1)^2 & = 2
	\end{alignedat}
	\right.
\end{equation*}

Riscriviamo il sistema lineare in forma matriciale indicando con $V$ la matrice dei coefficienti, $a$ il vettore delle incognite e $y$ il vettore dei termini noti.

\[
V=
\begin{bmatrix}
	1 & -1 & 1 \\
	1 & 0 & 0 \\
	1 & 1 & 1
\end{bmatrix}
a=
\begin{bmatrix}
	a_{0} \\
	a_{1} \\
	a_{2}
\end{bmatrix}
y=
\begin{bmatrix}
	2 \\
	1 \\
	2
\end{bmatrix}
\]

Prima di procedere con la risoluzione, ci chiediamo se la soluzione esiste ed è unica sfruttando il teorema di \emph{Rouché-Capelli}. Calcoliamo il determinante della matrice dei coefficienti e verifichiamo che questo sia diverso da 0. In tal caso il rango della matrice sarà massimo e il sistema avrà una e una sola soluzione.

\[
det
\begin{pmatrix}
	1 & -1 & 1 \\
	1 & 0 & 0 \\
	1 & 1 & 1
\end{pmatrix}
=2 \ne 0
\]

Il sistema ha soluzione e questa è unica. Torniamo alla forma a \emph{sistema di equazioni} e procediamo alla risoluzione del sistema lineare mediante il metodo di sostituzione. Otteniamo il seguente risultato:

\[
	\begin{cases}
		a_{0} = 1 \\
		1-a_{1}+a_{2}=2 \\
		1+a_{1}+a_{2}=2
	\end{cases}
	\Rightarrow
	\begin{cases}
		a_{0} = 1 \\
		a_{1}=0 \\
		a_{2}=1
	\end{cases}
	\Rightarrow
	p(x)=1+x^2
\]

In questo esempio abbiamo visto come da tre punti siamo riusciti ad ottenere un polinomio di grado due.

\begin{esempio}
	Costruire una funzione $p(x)$ che passi per i punti assegnati $(x_0, y_0)=(-1,2), (x_1, y_1)=(0,2), (x_2, y_2)=(1,2)$.
\end{esempio}

Possiamo già dire che una funzione sicuramente passante per questi tre punti è $p(x)=2$. Per affinare le nostre abilità però ripetiamo il procedimento visto in precedenza. Scegliamo sempre un polinomio generico $p(x)=a_{0}+a_{1}x+a_{2}x^2$.

\begin{equation*}
	\left\{
	\begin{alignedat}{3}
		% R & L   &  R & L   &  R & L 
		a_{0} & +{} &  a_{1}(-1) & +{} & a_{2}(-1)^2 & = 2 \\
		a_{0} & +{} &  a_{1}(0) & +{} &  a_{2}(0)^2 & = 2 \\
		a_{0} & +{} & a_{1}(1) & +{} & a_{2}(1)^2 & = 2
	\end{alignedat}
	\right.
\end{equation*}

Se aguzziamo un po' la vista ci accorgiamo che la matrice dei coefficienti è esattamente uguale a quella di prima! Quindi sappiamo già che anche questo sistema ha una e una sola soluzione. L'unica cosa a cambiare in questo caso è il vettore dei termini noti.

\[
\begin{cases}
	a_{0} = 2 \\
	2-a_{1}+a_{2} = 2 \\
	2+a_{1}+a_{2} = 2
\end{cases}
\Rightarrow
\begin{cases}
	a_{0} = 2 \\
	a_{1} = 0 \\
	a_{2} = 0
\end{cases}
\Rightarrow
p(x)=2
\]

In questo caso da tre punti abbiamo ottenuto un polinomio di grado 0.

\begin{esempio}
	Costruire una funzione $p(x)$ che passi per i punti assegnati $(x_0, y_0)=(-1,-1), (x_1, y_1)=(0,0), (x_2, y_2)=(1,1)$.
\end{esempio}

In questo caso possiamo intuire che la funzione in questione sarà $p(x)=x$. Ricaviamola comunque con il solito gioco. Prendiamo il polinomio generico $p(x)=a_{0}+a_{1}x+a_{2}x^2$ e costruiamo il sistema di equazioni.

\begin{equation*}
	\left\{
	\begin{alignedat}{3}
		% R & L   &  R & L   &  R & L 
		a_{0} & +{} &  a_{1}(-1) & +{} & a_{2}(-1)^2 & = -1 \\
		a_{0} & +{} &  a_{1}(0) & +{} &  a_{2}(0)^2 & = 0 \\
		a_{0} & +{} & a_{1}(1) & +{} & a_{2}(1)^2 & = 1
	\end{alignedat}
	\right.
\end{equation*}

Anche in questo caso saltiamo a piedi pari il controllo dell'esistenza e unicità della soluzione, dato che la matrice dei coefficienti è sempre la stessa. Come prima, cambia solo il vettore dei termini noti.

\[
\begin{cases}
	a_{0} = 0 \\
	-a_{1}+a_{2} = -1 \\
	a_{1}+a_{2} = 1
\end{cases}
\Rightarrow
\begin{cases}
	a_{0} = 0 \\
	a_{1} = 1 \\
	a_{2} = 0
\end{cases}
\Rightarrow
p(x)=x
\]

In questo caso da tre punti abbiamo ottenuto un polinomio di grado 1. Finalmente, dopo aver visto alcuni semplici esempi, enunciamo i primi teoremi.

\begin{teorema*}[di Weierstrass]
	Sia $f(x)$ continua in $[a,b]$.  $\forall \varepsilon >0 \ \exists k \ : \ |p_{n_{\varepsilon}}(x) - f(x)| < \varepsilon$.
\end{teorema*}

Da non confondere con l'omonimo teorema di Weierstrass sull'esistenza dei massimi. Questo risultato ci dice che possiamo approssimare una funzione continua definita in un intervallo chiuso e limitato con un polinomio di grado opportuno.

\begin{teorema}
	Dati $n+1$ punti $x_{i}$ (con $i=0, \dots, n$) distinti ed $n+1$ numeri reali $y_{i}$ (con $i=0, ..., n$), esiste ed è unico il polinomio $p(x) \in \mathcal{P}_{n}$ tale che $p(x_{i})=y_{i}$ per $i=0,...,n$.
\end{teorema}

\begin{proof}
	Come abbiamo visto in precedenza, per costruire e ricavare il polinomio approssimante di $n+1$ punti  dobbiamo trovare i coefficienti del generico polinomio $p(x)=a_{0}+a_{1}x+\dots+a_{n}x^n$ che soddisfano il passaggio per tutti i punti assegnati. Come prima, costruiamo un sistema lineare di $n+1$ equazioni ed $n+1$ incognite.
	
	\begin{equation*}
		\left\{
		\begin{alignedat}{5}
			% R & L   &  R & L   &  R & L 
			a_{0} & +{} &  a_{1}x_{0} & +{} & a_{2}x_{0}^2 & +{} & \cdots & +{} & a_{n}x_{0}^n & = y_{0} \\
			a_{0} & +{} &  a_{1}x_{1} & +{} & a_{2}x_{1}^2 & +{} & \cdots & +{} & a_{n}x_{1}^n & = y_{1} \\
			a_{0} & +{} &  a_{1}x_{2} & +{} & a_{2}x_{2}^2 & +{} & \cdots & +{} & a_{n}x_{2}^n & = y_{2} \\
			\vdots \\
			a_{0} & +{} &  a_{1}x_{n} & +{} & a_{2}x_{n}^2 & +{} & \cdots & +{} & a_{n}x_{n}^n & = y_{n} \\
		\end{alignedat}
		\right.
	\end{equation*}
	
	Riscriviamo in forma matriciale.
	\[
	V=
	\begin{bmatrix}
		1 & x_{0} & x_{0}^2 & x_{0}^3 & \cdots & x_{0}^n \\
		1 & x_{1} & x_{1}^2 & x_{1}^3 & \cdots & x_{1}^n \\
		1 & x_{2} & x_{2}^2 & x_{2}^3 & \cdots & x_{2}^n \\
		\vdots & \vdots & \vdots & \vdots & \ddots & \vdots \\
		1 & x_{n} & x_{n}^2 & x_{n}^3 & \cdots & x_{n}^n \\
	\end{bmatrix}
	a=
	\begin{bmatrix}
		a_{0} \\
		a_{1} \\
		a_{2} \\
		\vdots \\
		a_{n}
	\end{bmatrix}
	y=
	\begin{bmatrix}
		y_{0} \\
		y_{1} \\
		y_{2} \\
		\vdots \\
		y_{n}
	\end{bmatrix}
	\]
	Come prima, vogliamo studiare l'esistenza ed unicità della soluzione attraverso il teorema di Rouché-Capelli. Se riusciamo a dimostrare che la matrice $V$ è non singolare, la soluzione è una e unica. 
	
	Procediamo per assurdo, ipotizziamo che la matrice V sia singolare e consideriamo un problema simile, cioè $V \cdot a=0$. In questo modo non dobbiamo più porci il problema dell'esistenza, perché è un sistema lineare omogeneo. L'unica cosa da chiedersi è l'unicità della soluzione.
	
	Abbiamo ipotizzato che la matrice $V$ sia singolare, quindi $\det V=0$. Questo significa che il vettore incognite $a$ sia non nullo e quindi avremo che $\exists \overline{a} : V \cdot \overline{a}=0$. Questo significa che se prendiamo il polinomio generico $p(x)=\overline{a_{0}} + \overline{a_{1}}x + \overline{a_{2}}x^2 + \cdots + \overline{a_{n}}x^n$ e riscriviamo il sistema lineare avremo che:
	\begin{equation*}
	\left\{
	\begin{alignedat}{6}
		% R & L   &  R & L   &  R & L 
		p(x_{0}) & = \overline{a_{0}} & +{} &  \overline{a_{1}}x_{0} & +{} & \overline{a_{2}}x_{0}^2 & +{} & \cdots & +{} & \overline{a_{n}}x_{0}^n & = 0 \\
		p(x_{1}) & = \overline{a_{0}} & +{} &  \overline{a_{1}}x_{1} & +{} & \overline{a_{2}}x_{1}^2 & +{} & \cdots & +{} & \overline{a_{n}}x_{1}^n & = 0 \\
		p(x_{2}) & = \overline{a_{0}} & +{} &  \overline{a_{1}}x_{2} & +{} & \overline{a_{2}}x_{2}^2 & +{} & \cdots & +{} & \overline{a_{n}}x_{2}^n & = 0 \\
		\vdots \\
		p(x_{n}) & = \overline{a_{0}} & +{} &  \overline{a_{1}}x_{n} & +{} & \overline{a_{2}}x_{n}^2 & +{} & \cdots & +{} & \overline{a_{n}}x_{n}^n & = 0 \\
	\end{alignedat}
	\right.
	\end{equation*}
	
	Questo significato viola il teorema fondamentale dell'algebra, in quanto un polinomio di grado $n$ avrebbe $n+1$ radici. Qui troviamo l'assurdo e di conseguenza la matrice $V$ è non singolare, dimostrando che la soluzione al sistema lineare originario esiste ed è unica.
\end{proof}
\begin{proof}[Dimostrazione alternativa]
	Per dimostrare l'esistenza e unicità del polinomio interpolante di grado minore o uguale ad $n$ possiamo introdurre un altro polinomio $q(x)$, oltre a $p(x)$, che interpoli i punti assegnati (i.e., $q(x_{i})=y_{i}$ con $i=0, 1, \dots, n$).
	
	Definiamo un terzo polinomio $r(x)=p(x)-q(x)$. Per costruzione il polinomio $r(x) \in \mathcal{P}_{n}$.
	
	In ogni punto $x_{i}$ entrambi i polinomi $p(x_{i})$ e $q(x_{i})$ assumono gli stessi valori, dato che entrambi interpolano gli stessi punti, quindi $r(x_{i})=p(x_{i})-q(x_{i}) = 0$ per $i=0, 1, \dots, n$. Questo però significa che $r(x)$ è un polinomio di grado al più $n$ che si annulla in $n+1$ punti. Questo viola il teorema fondamentale dell'algebra ed è assurdo. Il polinomio $p(x)$ è dunque unico.
\end{proof}

\subsection{La matrice di Vandermonde}
La $V$ che abbiamo incontrato in precedenza si dice \emph{matrice di Vandermonde}. Si può dimostrare che il determinante di questa matrice particolare si può calcolare nel seguente modo:
\[
\det V =
\prod_{j=0}^{n-1}
\prod_{i=j+1}^{n}
(x_{i}-x_{j})
\]
Siccome i punti $x_{i}$ sono distinti (i.e.\ $x_{i} \ne x_{j}$ se $i \ne j$), osserviamo che il determinante è sicuramente diverso da $0$.

Proseguiamo con qualche esempio di calcolo del determinante.
\begin{esempio}
	Calcoliamo il determinante di una generica matrice con $n = 3$, la matrice sarà dunque 4x4.
	\[
	\det V =
	\prod_{j=0}^{2}
	\prod_{i=j+1}^{3}
	(x_{i}-x_{j})
	\]

	\begin{align*}
	j = 0 & \qquad \prod_{i=1}^{3} (x_{i}-x_{0})=(x_{1}-x_{0})(x_{2}-x_{0})(x_{3}-x_{0}) \\
	j = 1 & \qquad \prod_{i=2}^{3} (x_{i}-x_{1})=(x_{2}-x_{1})(x_{3}-x_{1}) \\
	j = 2 & \qquad \prod_{i=3}^{3} (x_{i}-x_{2})=(x_{3}-x_{2})
	\end{align*}

	Di conseguenza, moltiplicando tutti i risultati ottenuti avremo:
	\[
	\det V =
	\prod_{j=0}^{2}
	\prod_{i=j+1}^{3}
	(x_{i}-x_{j})
	=
	(x_{1}-x_{0})(x_{2}-x_{0})(x_{3}-x_{0})(x_{2}-x_{1})(x_{3}-x_{1})(x_{3}-x_{2})	
	\]
	
	Notiamo che abbiamo ottenuto 6 fattori, quindi 5 moltiplicazioni da affrontare.
\end{esempio}

\subsubsection{Costo del calcolo del determinante della matrice V}
Riprendiamo uno schema simile a quello appena visto nell'esempio precedente.
\begin{align*}
	j = 0 & \qquad \prod_{i=1}^{n} (x_{i}-x_{0})=(x_{1}-x_{0})(x_{2}-x_{0})(x_{3}-x_{0}) \cdots (x_{n}-x_{0}) \\
	j = 1 & \qquad \prod_{i=2}^{3} (x_{i}-x_{1})=(x_{2}-x_{1})(x_{3}-x_{1}) \cdots (x_{n}-x_{1}) \\
	j = 2 & \qquad \prod_{i=3}^{3} (x_{i}-x_{2})=(x_{3}-x_{2}) \cdots (x_{n}-x_{2}) \\
	\vdots & \\
	j = (n-2) & \qquad \prod_{i=n-1}^{n} (x_{i}-x_{n-2})=(x_{n-1}-x_{n-2})(x_{n}-x_{n-2}) \\
	j = (n-1) & \qquad \prod_{i=n-1}^{n} (x_{i}-x_{n-1})=(x_{n}-x_{n-1}) \\
\end{align*}

Quando $j=0$ abbiamo $n$ fattori ed $n-1$ operazioni di prodotto, quando $j=1$ si hanno $n-1$ fattori e $n-2$ operazioni di prodotto. Proseguendo arriviamo con $j=n-2$ a $2$ fattori con una sola operazione di prodotto e a $j=n-1$ con un fattore e nessuna operazione di prodotto. Quindi avremo in totale $(n-1)+(n-2)+(\cdots)+1$ operazioni di prodotto. Usando la formula attribuita a Gauss \footnote{si dice che Gauss risolse il problema del calcolo della somma dei primi 100 numeri naturali all'età di sette anni} otteniamo un numero di operazioni pari a:
\[
\frac{(n-1+1)(n-1)}{2}=
\frac{(n-1)n}{2}=
\frac{n^{2}}{2}-\frac{n}{2}
\]

Dobbiamo ancora prendere in considerazione le moltiplicazioni vere e proprie, che sono $(n-1)$.
Il numero di operazioni totali è dunque:
\[
\frac{(n-1)n}{2}+(n-1)=
\frac{n^{2}}{2}-\frac{n}{2}+n-1
\]

La complessità del calcolo del determinante della matrice di Vandermonde è dunque $\mathcal{O}(\frac{n^2}{2})$.

Come comparazione, ricordiamo che la complessità del calcolo del determinante di Laplace è dell'ordine di $(n+1)!$. 

Se pensiamo inoltre che il calcolo del determinante di una matrice triangolare è dell'ordine di $\mathcal{O}(n)$ ci rendiamo conto che la struttura della matrice di Vandermonde è estremamente importante per quanto riguarda il costo e l'economia dei nostri algoritmi di risoluzione!

Ad esempio, ricordiamo che il procedimento di Gauss ci permette di trasformare una matrice qualsiasi in una triangolare con una complessità dell'ordine $\mathcal{O}(\frac{n^3}{3})$. Questo viene estremamente comodo per calcolare il determinante.

A questo punto è lecito chiedersi se possiamo costruire una matrice particolare in modo da facilitarci i conti, al posto di utilizzare la matrice di Vandermonde.

\subsection{Basi opportune}
Fino a questo momento i polinomi $p(x)$ che abbiamo usato sfruttavano la base canonica dei polinomi $\mathcal{P}_{n}$, quindi $(1, x, x^2, \cdots, x^n)$. Possiamo costruire una base opportuna che ci permetta di semplificare i conti? La risposta è sì.

Prima di vedere la risposta accurata a questa domanda, vediamo di arrivarci intuitivamente attraverso un esempio.

\begin{esempio}
	Prendo due punti $x_{0}$ e $x_{1}$ distinti (con $y_{0}$ e $y_{1}$ assegnati).
	Voglio costruire due polinomi, che chiameremo $L_{0}(x)$ ed $L_{1}(x)$, tali che
	\[
	L_{0}(x)=
	\begin{cases}
		1 & \text{se $x=x_{0}$} \\
		0 & \text{se $x=x_{1}$}
	\end{cases}
	\quad
	L_{1}(x)=
	\begin{cases}
		1 & \text{se $x=x_{1}$} \\
		0 & \text{se $x=x_{0}$}
	\end{cases}
	\]
	
	Se vogliamo che il polinomio $L_{0}(x)$ si annulli in $x_{1}$, possiamo definirlo come $L_{0}(x)=x-x_{1}$. Vogliamo però che questo valga esattamente 1 in $x_{0}$. Introduciamo dunque la costante $\alpha_{0}$ e definiamo $L_{0}(x)=\alpha_{0}(x-x_{1})$: quando $x=x_{1}$ il polinomio varrà comunque $0$. Imponiamo $L_{0}(x_{0})=1=\alpha_{0}(x_{0}-x_{1})$.
	Abbiamo quindi:
	\[
	\alpha_{0}=\frac{1}{x_{0}-x_{1}}
	\quad
	L_{0}(x)=\frac{x-x_{1}}{x_{0}-x_{1}}
	\]
	
	Seguendo un ragionamento simile per $L_{1}(x)$ definiamo $L_{1}(x)=\alpha_{1}(x-x_{0})$. Avremo dunque:
	\[
	\alpha_{1}=\frac{1}{x_{1}-x_{0}}
	\quad
	L_{1}(x)=\frac{x-x_{0}}{x_{1}-x_{0}}
	\]
	
	Per formare una base, i polinomi $L_{0}(x)$ ed $L_{1}(x)$ devono essere \emph{linearmente indipendenti}, cioè deve valere che:
	
	\[
	c_{0}L_{0}(x)+c_{1}L_{1}(x)=0 \Rightarrow c_{0}, c_{1} = 0
	\]
	
	Possiamo dimostrarlo in maniera molto semplice: cerchiamo i valori di $c_{0}$ e $c{1}$ tali che soddisfino il seguente sistema:
	
	\[
	\begin{cases}
		c_{0}L_{0}(x_{0})+c_{1}L_{1}(x_{0})=0 \\
		c_{0}L_{0}(x_{1})+c_{1}L_{1}(x_{1})=0
	\end{cases}
	\Rightarrow
	\begin{cases}
		c_{0} \cdot 1 + c_{1} \cdot 0=0 \\
		c_{0} \cdot 0 + c_{1} \cdot 1=0
	\end{cases}
	\Rightarrow
	\begin{cases}
		c_{0}=0 \\
		c_{1}=0
	\end{cases}
	\]
	
	Il polinomio che sostituirà il polinomio formato dai monomi (base canonica) usato finora sarà dunque della forma:
	\[
	p(x) = b_{0}L_{0}(x) + b_{1}L_{1}(x) \qquad p(x) \in \mathcal{P}_{1}
	\]
	
	Usando i soliti strumenti risolutivi, imponiamo il passaggio per i punti $(x_{0}, y_{0})$ e $(x_{1}, y_{1})$.
	
	\[
	\begin{cases}
		y_{0}=p(x_{0})=b_{0}L_{0}(x_{0})+b_{1}L_{1}(x_{0}) \\
		y_{1}=p(x_{1})=b_{0}L_{0}(x_{1})+b_{1}L_{1}(x_{1})
	\end{cases}
	\]
	Passiamo ancora una volta alla forma matriciale del sistema lineare appena descritto.
	\[
	V=
	\begin{bmatrix}
		L_{0}(x_{0}) & L_{1}(x_{0}) \\
		L_{0}(x_{1}) & L_{1}(x_{1}) 
	\end{bmatrix}
	a=
	\begin{bmatrix}
		b_{0}\\
		b_{1}
	\end{bmatrix}
	y=
	\begin{bmatrix}
		y_{0}\\
		y_{1}
	\end{bmatrix}
	\]
	Se guardiamo attentamente la matrice V è in realtà la matrice identità! Quindi
	\[
	Ia=y \Leftrightarrow a=y
	\]
	
	In questo modo possiamo scrivere il polinomio interpolatore nella forma seguente:
	\[
	p(x)=y_{0}L_{0}(x)+y_{1}L_{1}(x)
	\]
	I polinomi $L_{0}(x)$ e $L_{1}(x)$ si dicono \emph{Lagrangiani}.
\end{esempio}
Il polinomio trovato con il metodo della matrice di Vandermonde e quello individuato con il metodo dei polinomi Lagrangiani è lo stesso, per il teorema dell'unicità.

\begin{esempio}
	Per consolidare le nostre conoscenze, consideriamo ora 3 punti $(x_{0}, y_{0}), (x_{1}, y_{1}), (x_{2}, y_{2})$ \emph{distinti}.
	
	Se dovessimo usare la base canonica (e la matrice di Vandermonde) avremmo
	\begin{equation*}
		\left\{
		\begin{alignedat}{3}
			% R & L   &  R & L   &  R & L 
			a_{0} & +{} &  a_{1}x_{0} & +{} & a_{2}x_{0}^2 & = y_{0} \\
			a_{0} & +{} &  a_{1}x_{1} & +{} &  a_{2}x_{1}^2 & = y_{1} \\
			a_{0} & +{} & a_{1}x_{2} & +{} & a_{2}x_{2}^2 & = y_{2}
		\end{alignedat}
		\right.
	\end{equation*}
	
	Riscriviamo il sistema lineare in forma matriciale indicando con $V$ la matrice dei coefficienti, $a$ il vettore delle incognite e $y$ il vettore dei termini noti.
	
	\[
	V=
	\begin{bmatrix}
		1 & x_{0} & x_{0}^2 \\
		1 & x_{1} & x_{1}^2 \\
		1 & x_{2} & x_{2}^2 
	\end{bmatrix}
	a=
	\begin{bmatrix}
		a_{0} \\
		a_{1} \\
		a_{2}
	\end{bmatrix}
	y=
	\begin{bmatrix}
		y_{0} \\
		y_{1} \\
		y_{2}
	\end{bmatrix}
	\qquad
	Va=y
	\]
	
	Ricordiamo che tutte le volte che calcolo V con il metodo della matrice di Vandermonde, non devo chiedermi se la soluzione esiste ed è unica, perché abbiamo visto come questo sia coperto dal teorema dell'esistenza e unicità.
	
	Usiamo ora il nuovo metodo! Creiamo una base opportuna, provando a costruire $L_{0}$, $L_{1}$, $L_{2}$, appartenenti a $\mathcal{P}_{2}$, con le proprietà viste sopra nell'esempio precedente.
	
	\[
	L_{0}(x)=
	\begin{cases}
		1 & \text{se $x=x_{0}$} \\
		0 & \text{se $x=x_{1},x_{2}$}
	\end{cases}
	\quad
	L_{1}(x)=
	\begin{cases}
		1 & \text{se $x=x_{1}$} \\
		0 & \text{se $x=x_{0},x_{2}$}
	\end{cases}
	\quad
		L_{1}(x)=
	\begin{cases}
		1 & \text{se $x=x_{2}$} \\
		0 & \text{se $x=x_{0},x_{1}$}
	\end{cases}
	\]
	Prendendo spunto da quanto fatto sopra, modelliamo il primo polinomio $L_{0}$ in modo che si annulli in $x_{1}$ e $x_{2}$. Un polinomio che soddisfa queste due condizioni è 
	\[
	L_{0}(x)=\alpha_{0}(x-x_{1})(x-x_{2})
	\]
	dove $\alpha_{0}$ è una costante generica. Vogliamo che $L_{0}$ valga $1$ in $x_{0}$, quindi sfruttiamo questo vincolo per calcolare $\alpha_{0}$.
	\[
	L_{0}(x_{0})=1=\alpha_{0}(x_{0}-x_{1})(x_{0}-x_{2}) \Rightarrow \alpha_{0}=\frac{1}{(x_{0}-x_{1})(x_{0}-x_{2})}
	\]
	Mettendo tutto insieme otteniamo il polinomio $L_{0}(x)$.
	\[
		L_{0}(x)=\frac{(x-x_{1})(x-x_{2})}{(x_{0}-x_{1})(x_{0}-x_{2})}
	\]
	Facciamo un ragionamento simile per $L_{1}(x)$ e $L_{2}(x)$. Vogliamo che $L_{1}(x)$ si annulli in $x_{0}$ e $x_{2}$.
	\[
	L_{1}(x)=\alpha_{1}(x-x_{0})(x-x_{2})
	\]
	$\alpha_{1}$ è una costante generica. Calcoliamo $\alpha_{1}$ usando il vincolo $L_{1}(x_{1})=1$.
	\[
	L_{1}(x_{1})=1=\alpha_{1}(x_{1}-x_{0})(x_{1}-x_{2}) \Rightarrow \alpha_{1}=\frac{1}{(x_{1}-x_{0})(x_{1}-x_{2})}
	\]
	Mettendo insieme il tutto otteniamo
	\[
	L_{1}(x)=\frac{(x-x_{0})(x-x_{2})}{(x_{1}-x_{0})(x_{1}-x_{2})}
	\]
	Glissando sui passaggi, è facile ottenere $L_{2}(x)$.
	\[
	L_{2}(x)=\frac{(x-x_{0})(x-x_{1})}{(x_{2}-x_{0})(x_{2}-x_{1})}
	\]
\end{esempio}
\subsubsection{Generalizziamo per n+1 punti}
Prendiamo $n+1$ punti \emph{distinti}. Voglio usare una base corretta per sostituire quella dei monomi usata finora. Quindi costruisco $n+1$ polinomi $L_{i}(x)$ con $i=0,\cdots,n$, tali che
\[
\begin{array}{l}
L_{0}(x)=
\begin{cases}
	1 & \text{se $x=x_{0}$} \\
	0 & \text{se $x=x_{1},x_{2},\cdots,x_{n}$}
\end{cases}
\\
\quad
\\
L_{1}(x)=
\begin{cases}
	1 & \text{se $x=x_{1}$} \\
	0 & \text{se $x=x_{0},x_{2},\cdots,x_{n}$}
\end{cases}
\\
\vdots
\\
L_{i}(x)=
\begin{cases}
	1 & \text{se $x=x_{i}$} \\
	0 & \text{se $x=x_{0},x_{1},\cdots,x_{i-1},x_{i+1},\cdots,x_{n}$}
\end{cases}
\\
\vdots
\\
L_{n}(x)=
\begin{cases}
	1 & \text{se $x=x_{n}$} \\
	0 & \text{se $x=x_{0},x_{1},\cdots,x_{n-1}$}
\end{cases}
\end{array}
\]
Sfruttando i concetti visti prima cerchiamo di trovare la forma dei vari polinomi. Partiamo con $L_{0}(x)$.

\begin{align*}
	& L_{0}(x) = \alpha_{0}(x-x_{1})(x-x_{2}) \cdots (x-x_{n}) \\
	& L_{0}(x_{0}) = 1 = \alpha_{0}(x_{0}-x_{1})(x_{0}-x_{2}) \cdots (x-x_{n}) \\
	& \alpha_{0}=\frac{1}{(x_{0}-x_{1})(x_{0}-x_{2}) \cdots (x-x_{n})} \\
	& L_{0}(x)=\frac{(x-x_{1})(x-x_{2}) \cdots (x-x_{n})}{(x_{0}-x_{1})(x_{0}-x_{2}) \cdots (x-x_{n})}
\end{align*}
Riscriviamo in maniera più compatta
\[
L_{0}(x)=
\prod_{j=0,j \ne 0}^{n}
\frac{(x-x_{j})}{(x_{0}-x_{j})}
\]
\end{document}
